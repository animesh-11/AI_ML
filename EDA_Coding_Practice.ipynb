{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkC7sZmKw4m+1M76jIlFRr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/animesh-11/AI_ML/blob/main/EDA_Coding_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0HbRMyhnNWG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# NOTE: This global df_sales is from a previous problem and is not used in the solution below.\n",
        "# The solution uses the filename passed to the aggregate_monthly_sales function.\n",
        "\n",
        "def aggregate_monthly_sales(input_tuple, filename='https://d3ejq4mxgimsmf.cloudfront.net/Product_sales_data-9f83ae7a11c340d1884ae214aadbacac.csv'):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "    product_category, start_date_str, end_date_str = input_tuple\n",
        "\n",
        "    # Convert sale_date to datetime\n",
        "    df['sale_date'] = pd.to_datetime(df['sale_date'])\n",
        "\n",
        "    # Convert input dates to datetime\n",
        "    start_date = pd.to_datetime(start_date_str)\n",
        "    end_date = pd.to_datetime(end_date_str)\n",
        "\n",
        "    # Filter by product category and date range\n",
        "    filtered_df = df[\n",
        "        (df['product_category'] == product_category) &\n",
        "        (df['sale_date'] >= start_date) &\n",
        "        (df['sale_date'] <= end_date)\n",
        "    ].copy()\n",
        "\n",
        "    # Check if the date range spans more than one month\n",
        "    if start_date.to_period('M') == end_date.to_period('M'):\n",
        "        # Daily aggregation for a single calendar month\n",
        "        grouped_sales = filtered_df.groupby(filtered_df['sale_date'].dt.strftime('%Y-%m-%d'))['sales_amount'].sum().reset_index()\n",
        "        grouped_sales.columns = ['date', 'total_sales']\n",
        "    else:\n",
        "        # Monthly aggregation for multiple months\n",
        "        grouped_sales = filtered_df.groupby(filtered_df['sale_date'].dt.to_period('M'))['sales_amount'].sum().reset_index()\n",
        "        grouped_sales['date'] = grouped_sales['sale_date'].astype(str) + '-01'\n",
        "        grouped_sales = grouped_sales[['date', 'total_sales']]\n",
        "\n",
        "    # Round sales_amount to 2 decimal places\n",
        "    grouped_sales['total_sales'] = grouped_sales['total_sales'].round(2)\n",
        "\n",
        "    # Convert to list of tuples\n",
        "    result = list(grouped_sales.itertuples(index=False, name=None))\n",
        "    return result\n",
        "\n",
        "input_data = input()\n",
        "product_category, start_date, end_date = map(str.strip, input_data.split(','))\n",
        "output = aggregate_monthly_sales((product_category, start_date, end_date))\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b982ecf"
      },
      "source": [
        "def identify_invalid_email(record):\n",
        "    \"\"\"\n",
        "    Scans the provided data entry (a dictionary with the candidate name and their email ID)\n",
        "    and replaces their email ID with a string 'invalid' if it is invalid according to specific rules.\n",
        "    If not, the email ID is unmodified.\n",
        "\n",
        "    Args:\n",
        "        record (dict): A dictionary with keys 'Candidate Name' and 'Email ID'.\n",
        "                       The values are the candidate's name (str) and their email ID (str) respectively.\n",
        "\n",
        "    Returns:\n",
        "        dict: The dictionary after updating the email ID if it's invalid.\n",
        "    \"\"\"\n",
        "    email_id = record.get('Email ID')\n",
        "\n",
        "    # Rule 1: It is a non-empty string\n",
        "    if not email_id:\n",
        "        record['Email ID'] = 'invalid'\n",
        "        return record\n",
        "\n",
        "    # Rule 2: It must contain both an '@' symbol and a '.' symbol\n",
        "    if '@' not in email_id or '.' not in email_id:\n",
        "        record['Email ID'] = 'invalid'\n",
        "        return record\n",
        "\n",
        "    at_index = email_id.find('@')\n",
        "    dot_index = email_id.find('.')\n",
        "\n",
        "    # Rule 3: The '.' symbol must come after the '@' symbol with at least one character in between them\n",
        "    # (dot_index > at_index + 1)\n",
        "    if not (at_index != -1 and dot_index != -1 and dot_index > at_index + 1):\n",
        "        record['Email ID'] = 'invalid'\n",
        "        return record\n",
        "\n",
        "    return record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f16a267"
      },
      "source": [
        "Let's test the function with the example cases provided and additional scenarios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ab23c54"
      },
      "source": [
        "# Testcase 1\n",
        "input_record_1 = {'Candidate Name': 'Nikhil', 'Email ID': 'nikhil98singhdomain.com'}\n",
        "expected_output_1 = {'Candidate Name': 'Nikhil', 'Email ID': 'invalid'}\n",
        "result_1 = identify_invalid_email(input_record_1)\n",
        "print(f\"Testcase 1 Input: {input_record_1}\")\n",
        "print(f\"Testcase 1 Output: {result_1}\")\n",
        "print(f\"Testcase 1 Expected: {expected_output_1}\")\n",
        "print(f\"Testcase 1 {'PASS' if result_1 == expected_output_1 else 'FAIL'}\\n\")\n",
        "\n",
        "# Testcase 2\n",
        "input_record_2 = {'Candidate Name': 'Dravid', 'Email ID': 'dravidlee@domaincom'}\n",
        "expected_output_2 = {'Candidate Name': 'Dravid', 'Email ID': 'invalid'}\n",
        "result_2 = identify_invalid_email(input_record_2)\n",
        "print(f\"Testcase 2 Input: {input_record_2}\")\n",
        "print(f\"Testcase 2 Output: {result_2}\")\n",
        "print(f\"Testcase 2 Expected: {expected_output_2}\")\n",
        "print(f\"Testcase 2 {'PASS' if result_2 == expected_output_2 else 'FAIL'}\\n\")\n",
        "\n",
        "# Additional Test Case 3: Valid Email\n",
        "input_record_3 = {'Candidate Name': 'John Doe', 'Email ID': 'john.doe@example.com'}\n",
        "expected_output_3 = {'Candidate Name': 'John Doe', 'Email ID': 'john.doe@example.com'}\n",
        "result_3 = identify_invalid_email(input_record_3)\n",
        "print(f\"Testcase 3 Input: {input_record_3}\")\n",
        "print(f\"Testcase 3 Output: {result_3}\")\n",
        "print(f\"Testcase 3 Expected: {expected_output_3}\")\n",
        "print(f\"Testcase 3 {'PASS' if result_3 == expected_output_3 else 'FAIL'}\\n\")\n",
        "\n",
        "# Additional Test Case 4: Email with '.' before '@'\n",
        "input_record_4 = {'Candidate Name': 'Alice', 'Email ID': 'alice.example@com'}\n",
        "expected_output_4 = {'Candidate Name': 'Alice', 'Email ID': 'invalid'}\n",
        "result_4 = identify_invalid_email(input_record_4)\n",
        "print(f\"Testcase 4 Input: {input_record_4}\")\n",
        "print(f\"Testcase 4 Output: {result_4}\")\n",
        "print(f\"Testcase 4 Expected: {expected_output_4}\")\n",
        "print(f\"Testcase 4 {'PASS' if result_4 == expected_output_4 else 'FAIL'}\\n\")\n",
        "\n",
        "# Additional Test Case 5: Email with '.' immediately after '@'\n",
        "input_record_5 = {'Candidate Name': 'Bob', 'Email ID': 'bob@.com'}\n",
        "expected_output_5 = {'Candidate Name': 'Bob', 'Email ID': 'invalid'}\n",
        "result_5 = identify_invalid_email(input_record_5)\n",
        "print(f\"Testcase 5 Input: {input_record_5}\")\n",
        "print(f\"Testcase 5 Output: {result_5}\")\n",
        "print(f\"Testcase 5 Expected: {expected_output_5}\")\n",
        "print(f\"Testcase 5 {'PASS' if result_5 == expected_output_5 else 'FAIL'}\\n\")\n",
        "\n",
        "# Additional Test Case 6: Empty Email ID\n",
        "input_record_6 = {'Candidate Name': 'Charlie', 'Email ID': ''}\n",
        "expected_output_6 = {'Candidate Name': 'Charlie', 'Email ID': 'invalid'}\n",
        "result_6 = identify_invalid_email(input_record_6)\n",
        "print(f\"Testcase 6 Input: {input_record_6}\")\n",
        "print(f\"Testcase 6 Output: {result_6}\")\n",
        "print(f\"Testcase 6 Expected: {expected_output_6}\")\n",
        "print(f\"Testcase 6 {'PASS' if result_6 == expected_output_6 else 'FAIL'}\\n\")\n",
        "\n",
        "# Additional Test Case 7: Missing both '@' and '.'\n",
        "input_record_7 = {'Candidate Name': 'David', 'Email ID': 'davidexamplecom'}\n",
        "expected_output_7 = {'Candidate Name': 'David', 'Email ID': 'invalid'}\n",
        "result_7 = identify_invalid_email(input_record_7)\n",
        "print(f\"Testcase 7 Input: {input_record_7}\")\n",
        "print(f\"Testcase 7 Output: {result_7}\")\n",
        "print(f\"Testcase 7 Expected: {expected_output_7}\")\n",
        "print(f\"Testcase 7 {'PASS' if result_7 == expected_output_7 else 'FAIL'}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are working as an analyst in an aviation company. You have records of historical passenger counts for the flights from 1949 to 1960. Your task is to compute the mean number of passengers per year for this duration. You will be using a dataset that contains the two key pieces of information which are stored in their respective columns.\n",
        "\n",
        "\n",
        "\n",
        "Here is the data description\n",
        "\n",
        "'Month': This is a column with str entries that represent the year and the month for the record. For instance, the first entry in this column is the string '1949-01'.\n",
        "'Passengers': This is a column with int entries that represent the number of passengers catered to in that specific month and year. For instance, the first entry in this column is the integer 112.\n",
        "The number of rows in the data is 144.\n",
        "\n",
        "\n",
        "Compute the mean number of passengers per year and store the results year-wise in a Pandas Series mean_passengers_by_year.\n",
        "\n",
        "\n",
        "\n",
        "Note: The test cases for this question will check specific values in the computed series. The inputs for the test cases are the index labels for the computed series, and the outputs are the expected values of your series in those locations.\n",
        "\n",
        "\n",
        "\n",
        "Input format\n",
        "\n",
        "The year (for example, 1955)\n",
        "\n",
        "\n",
        "Output format\n",
        "\n",
        "The expected cell value at the target location as specified in the input label\n",
        "\n",
        "\n",
        "Constraints\n",
        "\n",
        "The index of the computed series is the year\n",
        "\n",
        "\n",
        "Testcases\n",
        "\n",
        "\n",
        "\n",
        "Testcase 1\n",
        "\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "1949\n",
        "\n",
        "\n",
        "\n",
        "Expected Output\n",
        "\n",
        "127\n",
        "\n",
        "\n",
        "\n",
        "Testcase 2\n",
        "\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "1950\n",
        "\n",
        "\n",
        "\n",
        "Expected Output\n",
        "\n",
        "140"
      ],
      "metadata": {
        "id": "p3xUATsyoins"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data from the provided URL\n",
        "df = pd.read_csv('https://d3ejq4mxgimsmf.cloudfront.net/AirPassengers-1eaa575774ad408691e22a1edfcab2ec.csv')\n",
        "\n",
        "# Convert 'Month' to datetime objects to easily extract the year\n",
        "df['Year'] = pd.to_datetime(df['Month']).dt.year\n",
        "\n",
        "# Group by 'Year' and compute the mean number of passengers\n",
        "mean_passengers_by_year = df.groupby('Year')['Passengers'].mean()\n",
        "\n",
        "# Display the result for verification\n",
        "print(mean_passengers_by_year)\n",
        "\n",
        "# Example Test Case Verification\n",
        "# The expected values are based on the original problem statement's test cases\n",
        "print(f\"\\nTestcase 1 (1949) Expected: 127, Actual: {mean_passengers_by_year.loc[1949]:.0f}\")\n",
        "print(f\"Testcase 2 (1950) Expected: 140, Actual: {mean_passengers_by_year.loc[1950]:.0f}\")"
      ],
      "metadata": {
        "id": "kdYUd8arojPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a reporter for a renowned chess magazine, your task is to identify the top grandmasters in each federation, typically defined as the country in which the grandmasters compete the most. Specifically, you need to determine which grandmasters in each federation have a rating greater than or equal to the mean rating of that federation.\n",
        "\n",
        "\n",
        "\n",
        "The dataset is from March 2025 and contains 10 columns and 1303 rows. However, for this analysis, you need to only consider the following columns:\n",
        "\n",
        "'Fed': This is a column with str entries that represent the federation which the grandmaster is a part of. For instance, 'IND' refers to the All India Chess Federation.\n",
        "'Rating': This is a column with int entries that represent the Elo rating of the grandmaster. The Elo rating system measures the relative strength of a player in some games, such as chess, compared to other players. For instance, Magnus Carlsen, the highest-rated player in this dataset, has an Elo rating of 2833.\n",
        "'Name': This is a column with str entries which represent the name of the grandmaster. For instance, 'Carlsen, Magnus'.\n",
        "All the three columns 'Fed', 'Name', 'Rating' contain valid and complete data\n",
        "\n",
        "\n",
        "Create a Pandas Series, players_above_mean, where the index represents the federation and the values are lists of grandmasters' names whose ratings are greater than or equal to the average Elo rating of that federation.\n",
        "\n",
        "\n",
        "\n",
        "Note: The test cases for this question will check specific values in the computed series. The inputs for the test cases are the index labels (federations) for the computed series, and the outputs are the expected values (lists of grandmasters' names) of your series in those locations.\n",
        "\n",
        "\n",
        "\n",
        "Input format\n",
        "\n",
        "The federation\n",
        "\n",
        "\n",
        "Output format\n",
        "\n",
        "The expected cell value at the target location as specified in the input label\n",
        "The dataset is already sorted in descending order of Elo rating; the output lists must preserve this order\n",
        "\n",
        "\n",
        "Constraints\n",
        "\n",
        "N/A\n",
        "\n",
        "\n",
        "Sample Testcases\n",
        "\n",
        "\n",
        "\n",
        "Testcase 1\n",
        "\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "NOR\n",
        "\n",
        "\n",
        "\n",
        "Expected Output\n",
        "\n",
        "['Carlsen, Magnus', 'Christiansen, Johan-Sebastian', 'Tari, Aryan', 'Hammer, Jon Ludvig', 'Agdestein, Simen', 'Urkedal, Frode Olav Olsen', 'Amar, Elham']\n",
        "\n",
        "\n",
        "\n",
        "Testcase 2\n",
        "\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "IND\n",
        "\n",
        "\n",
        "\n",
        "Expected Output\n",
        "\n",
        "['Gukesh D', 'Erigaisi Arjun', 'Praggnanandhaa R', 'Anand, Viswanathan', 'Aravindh, Chithambaram VR.', 'Vidit, Santosh Gujrathi', 'Harikrishna, Pentala', 'Nihal Sarin', 'Sadhwani, Raunak', 'Karthikeyan, Murali', 'Mendonca, Leon Luke', 'Puranik, Abhimanyu', 'Narayanan S L', 'Aryan Chopra', 'Pranav, V', 'Pranesh M', 'Gupta, Abhijeet', 'Ganguly, Surya Shekhar', 'Ghosh, Diptayan', 'Vaibhav, Suri', 'Bharath Subramaniyam H', 'Iniyan, Pa', 'Karthik Venkataraman', 'Gopal G.N.', 'Adhiban, B.', 'Aditya Mittal', 'Sethuraman, S.P.', 'Sasikiran, Krishnan', 'Sankalp Gupta', 'Pranav Anand', 'Vignesh N R', 'Harsha Bharathakoti', 'Raja Rithvik R', 'Koneru, Humpy']"
      ],
      "metadata": {
        "id": "nsrgnhPrp5wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from the provided URL\n",
        "df = pd.read_csv('https://d3ejq4mxgimsmf.cloudfront.net/active_grandmasters_March25-b0e7a64fd25c48ab8f380debb40e8a0a.csv')\n",
        "\n",
        "# Calculate the mean rating for each federation\n",
        "mean_ratings_by_fed = df.groupby('Fed')['Rating'].mean()\n",
        "\n",
        "# Function to get players above or equal to the mean rating for a given federation\n",
        "def get_players_above_mean(federation_df, mean_rating):\n",
        "    return federation_df[federation_df['Rating'] >= mean_rating]['Name'].tolist()\n",
        "\n",
        "# Create an empty dictionary to store the results\n",
        "players_above_mean_dict = {}\n",
        "\n",
        "# Iterate through each federation and apply the logic\n",
        "for fed, mean_rating in mean_ratings_by_fed.items():\n",
        "    federation_df = df[df['Fed'] == fed]\n",
        "    players_above_mean_dict[fed] = get_players_above_mean(federation_df, mean_rating)\n",
        "\n",
        "# Convert the dictionary to a Pandas Series\n",
        "players_above_mean = pd.Series(players_above_mean_dict)\n",
        "\n",
        "# Display the resulting Series\n",
        "print(players_above_mean)\n",
        "\n",
        "# Testcase 1 Verification (NOR)\n",
        "expected_nor = ['Carlsen, Magnus', 'Christiansen, Johan-Sebastian', 'Tari, Aryan', 'Hammer, Jon Ludvig', 'Agdestein, Simen', 'Urkedal, Frode Olav Olsen', 'Amar, Elham']\n",
        "actual_nor = players_above_mean.loc['NOR']\n",
        "print(f\"\\nTestcase 1 (NOR) Expected: {expected_nor}\")\n",
        "print(f\"Testcase 1 (NOR) Actual: {actual_nor}\")\n",
        "print(f\"Testcase 1 {'PASS' if actual_nor == expected_nor else 'FAIL'}\")\n",
        "\n",
        "# Testcase 2 Verification (IND)\n",
        "expected_ind = [\n",
        "    'Gukesh D', 'Erigaisi Arjun', 'Praggnanandhaa R', 'Anand, Viswanathan',\n",
        "    'Aravindh, Chithambaram VR.', 'Vidit, Santosh Gujrathi', 'Harikrishna, Pentala',\n",
        "    'Nihal Sarin', 'Sadhwani, Raunak', 'Karthikeyan, Murali', 'Mendonca, Leon Luke',\n",
        "    'Puranik, Abhimanyu', 'Narayanan S L', 'Aryan Chopra', 'Pranav, V', 'Pranesh M',\n",
        "    'Gupta, Abhijeet', 'Ganguly, Surya Shekhar', 'Ghosh, Diptayan', 'Vaibhav, Suri',\n",
        "    'Bharath Subramaniyam H', 'Iniyan, Pa', 'Karthik Venkataraman', 'Gopal G.N.',\n",
        "    'Adhiban, B.', 'Aditya Mittal', 'Sethuraman, S.P.', 'Sasikiran, Krishnan',\n",
        "    'Sankalp Gupta', 'Pranav Anand', 'Vignesh N R', 'Harsha Bharathakoti',\n",
        "    'Raja Rithvik R', 'Koneru, Humpy'\n",
        "]\n",
        "actual_ind = players_above_mean.loc['IND']\n",
        "print(f\"\\nTestcase 2 (IND) Expected: {expected_ind}\")\n",
        "print(f\"Testcase 2 (IND) Actual: {actual_ind}\")\n",
        "print(f\"Testcase 2 {'PASS' if actual_ind == expected_ind else 'FAIL'}\")"
      ],
      "metadata": {
        "id": "Lv0F3N7Np6cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are a Data Analyst at a retail company that tracks sales across various product categories. Your task is to analyze sales trends for a specific category over a given time period to support decisions on promotions and inventory planning.\n",
        "\n",
        "\n",
        "\n",
        "You are provided with a dataset containing\n",
        "\n",
        "- sale_date: Date of the sale (YYYY-MM-DD), ranging from 2024-01-01 to 2024-12-31 in string format\n",
        "\n",
        "- product_category: Category of the product sold, one of Electronics, Furniture, or Clothing in string format\n",
        "\n",
        "- sales_amount: Value of the sale (float value between 100.00 and 1000.00)\n",
        "\n",
        "\n",
        "\n",
        "Task\n",
        "\n",
        "- Implement a function aggregate_monthly_sales(input_tuple) that:\n",
        "\n",
        "- Accepts a tuple input: (product_category, start_date, end_date)\n",
        "\n",
        "- Filters the dataset based on the given product category and date range\n",
        "\n",
        "- Aggregates the sales data\n",
        "\n",
        "  - Daily, if the date range is within a single calendar month\n",
        "\n",
        "  - Monthly, if the date range spans more than one month\n",
        "\n",
        "- Returns a list of tuples [(YYYY-MM-DD, total_sales), ...] for daily or monthly aggregation\n",
        "\n",
        "\n",
        "\n",
        "Input Format\n",
        "\n",
        "- A tuple (product_category, start_date, end_date)\n",
        "\n",
        "\n",
        "\n",
        "Output Format\n",
        "\n",
        "- A list of tuples [(YYYY-MM-DD, total_sales_amount), ...]\n",
        "\n",
        "\n",
        "\n",
        "Constraints\n",
        "\n",
        "- Input must be a tuple in the format: (product_category, start_date, end_date)\n",
        "\n",
        "- Dates must be in YYYY-MM-DD format\n",
        "\n",
        "- Start date cannot be after end date\n",
        "\n",
        "- Every row in the dataset contains valid, complete data across all columns\n",
        "\n",
        "- There is no missing data in the dataset\n",
        "\n",
        "\n",
        "\n",
        "Examples\n",
        "\n",
        "\n",
        "\n",
        "Testcase 1\n",
        "\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "Electronics, 2024-01-01, 2024-01-31\n",
        "\n",
        "\n",
        "\n",
        "Expected Output\n",
        "\n",
        "[('2024-01-05', 735.21), ('2024-01-14', 827.28), ('2024-01-21', 705.59)]\n",
        "\n",
        "\n",
        "\n",
        "Testcase 2\n",
        "\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "Clothing, 2024-05-01, 2024-05-31\n",
        "\n",
        "\n",
        "\n",
        "Expected Output\n",
        "\n",
        "[('2024-05-05', 692.03), ('2024-05-20', 223.46), ('2024-05-24', 733.61), ('2024-05-31', 769.24)]"
      ],
      "metadata": {
        "id": "XKMyY3Her2mI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d3f5692"
      },
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# This function aggregates sales data for a given product category and date range.\n",
        "# It aggregates daily if the date range is within a single calendar month,\n",
        "# and monthly if the date range spans more than one month.\n",
        "# The filename parameter allows specifying the CSV file source.\n",
        "def aggregate_monthly_sales(input_tuple, filename='https://d3ejq4mxgimsmf.cloudfront.net/Product_sales_data-9f83ae7a11c340d1884ae214aadbacac.csv'):\n",
        "    # Read the CSV file into a pandas DataFrame\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "    # Unpack the input tuple into product category, start date string, and end date string\n",
        "    product_category, start_date_str, end_date_str = input_tuple\n",
        "\n",
        "    # Convert the 'sale_date' column in the DataFrame to datetime objects\n",
        "    df['sale_date'] = pd.to_datetime(df['sale_date'])\n",
        "\n",
        "    # Convert the input start and end date strings to datetime objects\n",
        "    start_date = pd.to_datetime(start_date_str)\n",
        "    end_date = pd.to_datetime(end_date_str)\n",
        "\n",
        "    # Filter the DataFrame based on the product category and the date range\n",
        "    filtered_df = df[\n",
        "        (df['product_category'] == product_category) &\n",
        "        (df['sale_date'] >= start_date) &\n",
        "        (df['sale_date'] <= end_date)\n",
        "    ].copy()\n",
        "\n",
        "    # Determine the aggregation level: daily or monthly\n",
        "    if start_date.to_period('M') == end_date.to_period('M'):\n",
        "        # If the date range is within a single calendar month, perform daily aggregation\n",
        "        # Group by the full date (YYYY-MM-DD) and sum the 'sales_amount'\n",
        "        grouped_sales = filtered_df.groupby(filtered_df['sale_date'].dt.strftime('%Y-%m-%d'))['sales_amount'].sum().reset_index()\n",
        "        # Rename the columns for clarity\n",
        "        grouped_sales.columns = ['date', 'total_sales']\n",
        "    else:\n",
        "        # If the date range spans multiple months, perform monthly aggregation\n",
        "        # Group by the year-month period and sum the 'sales_amount'\n",
        "        grouped_sales = filtered_df.groupby(filtered_df['sale_date'].dt.to_period('M'))['sales_amount'].sum().reset_index()\n",
        "        # Convert the Period object to a string in 'YYYY-MM-01' format for consistency with daily dates\n",
        "        grouped_sales['date'] = grouped_sales['sale_date'].astype(str) + '-01'\n",
        "        # Select and reorder columns\n",
        "        grouped_sales = grouped_sales[['date', 'total_sales']]\n",
        "\n",
        "    # Round the total sales amounts to 2 decimal places\n",
        "    grouped_sales['total_sales'] = grouped_sales['total_sales'].round(2)\n",
        "\n",
        "    # Convert the aggregated DataFrame to a list of tuples, where each tuple is (date, total_sales)\n",
        "    result = list(grouped_sales.itertuples(index=False, name=None))\n",
        "    return result\n",
        "\n",
        "# Example of how to use the function with user input:\n",
        "# The input() function would typically be used to get input from the user in a command-line environment.\n",
        "# In a notebook, you might manually define input_data or use widgets.\n",
        "# input_data = input('Enter product category, start date, end date (e.g., Electronics, 2024-01-01, 2024-01-31): ')\n",
        "\n",
        "# For demonstration purposes, let's use a hardcoded input:\n",
        "input_data_example = 'Electronics, 2024-01-01, 2024-01-31' # You can change this to test different scenarios\n",
        "product_category, start_date, end_date = map(str.strip, input_data_example.split(','))\n",
        "\n",
        "# Call the aggregate_monthly_sales function with the parsed input\n",
        "output = aggregate_monthly_sales((product_category, start_date, end_date))\n",
        "\n",
        "# Print the returned list of tuples\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are a Data Analyst at a retail company that tracks sales across various product categories. Your task is to analyze sales trends for a specific category over a given time period to support decisions on promotions and inventory planning.\n",
        "\n",
        "\n",
        "\n",
        "You are provided with a dataset containing\n",
        "\n",
        "- sale_date: Date of the sale (YYYY-MM-DD), ranging from 2024-01-01 to 2024-12-31 in string format\n",
        "\n",
        "- product_category: Category of the product sold, one of Electronics, Furniture, or Clothing in string format\n",
        "\n",
        "- sales_amount: Value of the sale (float value between 100.00 and 1000.00)\n",
        "\n",
        "\n",
        "\n",
        "Task\n",
        "\n",
        "- Implement a function aggregate_monthly_sales(input_tuple) that:\n",
        "\n",
        "- Accepts a tuple input: (product_category, start_date, end_date)\n",
        "\n",
        "- Filters the dataset based on the given product category and date range\n",
        "\n",
        "- Aggregates the sales data\n",
        "\n",
        "  - Daily, if the date range is within a single calendar month\n",
        "\n",
        "  - Monthly, if the date range spans more than one month\n",
        "\n",
        "- Returns a list of tuples [(YYYY-MM-DD, total_sales), ...] for daily or monthly aggregation\n",
        "\n",
        "\n",
        "\n",
        "Input Format\n",
        "\n",
        "- A tuple (product_category, start_date, end_date)\n",
        "\n",
        "\n",
        "\n",
        "Output Format\n",
        "\n",
        "- A list of tuples [(YYYY-MM-DD, total_sales_amount), ...]\n",
        "\n",
        "\n",
        "\n",
        "Constraints\n",
        "\n",
        "- Input must be a tuple in the format: (product_category, start_date, end_date)\n",
        "\n",
        "- Dates must be in YYYY-MM-DD format\n",
        "\n",
        "- Start date cannot be after end date\n",
        "\n",
        "- Every row in the dataset contains valid, complete data across all columns\n",
        "\n",
        "- There is no missing data in the dataset\n",
        "\n",
        "\n",
        "\n",
        "Examples\n",
        "\n",
        "\n",
        "\n",
        "Testcase 1\n",
        "\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "Electronics, 2024-01-01, 2024-01-31\n",
        "\n",
        "\n",
        "\n",
        "Expected Output\n",
        "\n",
        "[('2024-01-05', 735.21), ('2024-01-14', 827.28), ('2024-01-21', 705.59)]\n",
        "\n",
        "\n",
        "\n",
        "Testcase 2\n",
        "\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "Clothing, 2024-05-01, 2024-05-31\n",
        "\n",
        "\n",
        "\n",
        "Expected Output\n",
        "\n",
        "[('2024-05-05', 692.03), ('2024-05-20', 223.46), ('2024-05-24', 733.61), ('2024-05-31', 769.24)]"
      ],
      "metadata": {
        "id": "oLkzIOdWtRQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "def aggregate_monthly_sales(input_tuple, filename='https://d3ejq4mxgimsmf.cloudfront.net/Product_sales_data-9f83ae7a11c340d1884ae214aadbacac.csv'):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "    product_category, start_date_str, end_date_str = input_tuple\n",
        "\n",
        "    # Convert sale_date to datetime\n",
        "    df['sale_date'] = pd.to_datetime(df['sale_date'])\n",
        "\n",
        "    # Convert input dates to datetime\n",
        "    start_date = pd.to_datetime(start_date_str)\n",
        "    end_date = pd.to_datetime(end_date_str)\n",
        "\n",
        "    # Filter by product category and date range\n",
        "    filtered_df = df[\n",
        "        (df['product_category'] == product_category) &\n",
        "        (df['sale_date'] >= start_date) &\n",
        "        (df['sale_date'] <= end_date)\n",
        "    ].copy()\n",
        "\n",
        "    # Check if the date range spans more than one month\n",
        "    if start_date.to_period('M') == end_date.to_period('M'):\n",
        "        # Daily aggregation for a single calendar month\n",
        "        grouped_sales = filtered_df.groupby(filtered_df['sale_date'].dt.strftime('%Y-%m-%d'))['sales_amount'].sum().reset_index()\n",
        "        grouped_sales.columns = ['date', 'total_sales']\n",
        "    else:\n",
        "        # Monthly aggregation for multiple months\n",
        "        grouped_sales = filtered_df.groupby(filtered_df['sale_date'].dt.to_period('M'))['sales_amount'].sum().reset_index()\n",
        "        grouped_sales['date'] = grouped_sales['sale_date'].astype(str) + '-01'\n",
        "        grouped_sales = grouped_sales[['date', 'total_sales']]\n",
        "\n",
        "    # Round sales_amount to 2 decimal places\n",
        "    grouped_sales['total_sales'] = grouped_sales['total_sales'].round(2)\n",
        "\n",
        "    # Convert to list of tuples\n",
        "    result = list(grouped_sales.itertuples(index=False, name=None))\n",
        "    return result\n",
        "\n",
        "# The input() function will prompt for input when the cell is run\n",
        "input_data = input()\n",
        "product_category, start_date, end_date = map(str.strip, input_data.split(','))\n",
        "\n",
        "output = aggregate_monthly_sales((product_category, start_date, end_date))\n",
        "print(output)"
      ],
      "metadata": {
        "id": "fMT5h8eTtVIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are working as an energy analyst in a smart city initiative. You are provided with hourly electricity consumption data for 10 households (observations) over a 24-hour period. Each householdâ€™s usage is recorded as 24 hourly readings (features from 'Hour_0' to 'Hour_23'), representing electricity consumed in kilowatt-hours (kWh) in those hours.\n",
        "\n",
        "\n",
        "\n",
        "Implement a Python function analyze_household_peak_usage(household_id) to analyse the data for a specific household and identify:\n",
        "\n",
        "Which part of the day had the highest average energy consumption\n",
        "Which specific hour(s) in that segment had consumption above the segment's average\n",
        "\n",
        "\n",
        "The 24-hour day is segmented as follows:\n",
        "\n",
        "Column indices 0 to 5 of the data (12 AM to 5:59 AM) -> late night or early morning\n",
        "Column indices 6 to 11 of the data (6 AM to 11:59 AM) -> morning\n",
        "Column indices 12 to 17 of the data (12 PM to 5:59 PM) -> afternoon\n",
        "Column indices 18 to 23 of the data (6 PM to 11:59 PM) -> evening or night\n",
        "\n",
        "\n",
        "Dataset Description\n",
        "\n",
        "'Household_ID': Unique identifier for a household (str)\n",
        "'Hour_0', 'Hour_1', ..., 'Hour_23': Hourly electricity consumption values in kWh (int)\n",
        "\n",
        "\n",
        "Input Format\n",
        "\n",
        "The household ID (str)\n",
        "\n",
        "\n",
        "Output Format\n",
        "\n",
        "A dictionary with the following keys and values\n",
        "A key 'Peak Segment' with one of the following values suitably populated: 'Late Night/Early Morning', 'Morning', 'Afternoon', 'Evening/Night'\n",
        "A key 'High Usage Hours' whose value is a list of hours (int) extracted from the string column names of the hours, for instance, 'Hour_13' would be 13\n",
        "\n",
        "\n",
        "Constraints\n",
        "\n",
        "Input household ID must be in the range of 'Household_1' to 'Household_10' (both inclusive)\n",
        "There are no corrupt or missing values or duplicate observations in the data\n",
        "All values other than the household ID are numeric\n",
        "Household IDs are strings\n",
        "Dataset columns are consistently named from 'Hour_0' to 'Hour_23'\n",
        "No reordering or rearrangement of rows or columns is done\n",
        "\n",
        "\n",
        "Testcases\n",
        "\n",
        "\n",
        "\n",
        "Testcase 1\n",
        "\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "Household_3\n",
        "\n",
        "\n",
        "\n",
        "Expected Output\n",
        "\n",
        "{'Peak Segment': 'Evening/Night', 'High Usage Hours': [18, 19, 20, 22]}\n",
        "\n",
        "\n",
        "\n",
        "Testcase 2\n",
        "\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "Household_9\n",
        "\n",
        "\n",
        "\n",
        "Expected Output\n",
        "\n",
        "{'Peak Segment': 'Late Night/Early Morning', 'High Usage Hours': [0, 2, 4, 5]}"
      ],
      "metadata": {
        "id": "bwvRa4Pmw93e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def analyze_household_peak_usage(household_id):\n",
        "    \"\"\"\n",
        "    Analyzes hourly electricity consumption data for a specific household to identify\n",
        "    the peak usage segment and high usage hours within that segment.\n",
        "\n",
        "    Args:\n",
        "        household_id (str): The unique identifier for the household (e.g., 'Household_3').\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with 'Peak Segment' and 'High Usage Hours' keys.\n",
        "    \"\"\"\n",
        "    filename = 'https://d3ejq4mxgimsmf.cloudfront.net/hourly_energy_usage-9eb4bd3748964f8da8d95b54df732b1d.csv'\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "    # Filter data for the specific household\n",
        "    household_data = df[df['Household_ID'] == household_id].iloc[0]\n",
        "\n",
        "    # Define segments and their corresponding hour ranges and names\n",
        "    segments = {\n",
        "        'Late Night/Early Morning': (list(range(0, 6)), 'Hour_'),\n",
        "        'Morning': (list(range(6, 12)), 'Hour_'),\n",
        "        'Afternoon': (list(range(12, 18)), 'Hour_'),\n",
        "        'Evening/Night': (list(range(18, 24)), 'Hour_')\n",
        "    }\n",
        "\n",
        "    segment_averages = {}\n",
        "    # Calculate average consumption for each segment\n",
        "    for segment_name, (hours, prefix) in segments.items():\n",
        "        segment_columns = [f'{prefix}{h}' for h in hours]\n",
        "        segment_values = household_data[segment_columns]\n",
        "        segment_averages[segment_name] = segment_values.mean()\n",
        "\n",
        "    # Identify the peak segment (highest average consumption)\n",
        "    peak_segment_name = max(segment_averages, key=segment_averages.get)\n",
        "    peak_segment_hours, prefix = segments[peak_segment_name]\n",
        "    peak_segment_average = segment_averages[peak_segment_name]\n",
        "\n",
        "    # Identify high usage hours within the peak segment\n",
        "    high_usage_hours = []\n",
        "    for hour_int in peak_segment_hours:\n",
        "        hour_col = f'{prefix}{hour_int}'\n",
        "        if household_data[hour_col] > peak_segment_average:\n",
        "            high_usage_hours.append(hour_int)\n",
        "\n",
        "    return {\n",
        "        'Peak Segment': peak_segment_name,\n",
        "        'High Usage Hours': sorted(high_usage_hours) # Ensure hours are sorted\n",
        "    }\n",
        "\n",
        "# Testcase 1\n",
        "input_household_1 = 'Household_3'\n",
        "expected_output_1 = {'Peak Segment': 'Evening/Night', 'High Usage Hours': [18, 19, 20, 22]}\n",
        "result_1 = analyze_household_peak_usage(input_household_1)\n",
        "print(f\"Testcase 1 Input: {input_household_1}\")\n",
        "print(f\"Testcase 1 Output: {result_1}\")\n",
        "print(f\"Testcase 1 Expected: {expected_output_1}\")\n",
        "print(f\"Testcase 1 {'PASS' if result_1 == expected_output_1 else 'FAIL'}\\n\")\n",
        "\n",
        "# Testcase 2\n",
        "input_household_2 = 'Household_9'\n",
        "expected_output_2 = {'Peak Segment': 'Late Night/Early Morning', 'High Usage Hours': [0, 2, 4, 5]}\n",
        "result_2 = analyze_household_peak_usage(input_household_2)\n",
        "print(f\"Testcase 2 Input: {input_household_2}\")\n",
        "print(f\"Testcase 2 Output: {result_2}\")\n",
        "print(f\"Testcase 2 Expected: {expected_output_2}\")\n",
        "print(f\"Testcase 2 {'PASS' if result_2 == expected_output_2 else 'FAIL'}\\n\")"
      ],
      "metadata": {
        "id": "U_vk3aB7w-hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vXSl_AsLw_Fh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}