{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPB4rV+cnOx7qOTlKLg8SDu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/animesh-11/AI_ML/blob/main/Statistics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are a data analyst at a growing e-commerce company that regularly tracks daily sales across a weekly  reporting cycle. During one such weekly cycle, a system issue caused the loss of one day’s sales data. However, the average daily sales for the full 7-day period had already been calculated before the error occurred.\n",
        "\n",
        "\n",
        "To maintain accurate business reporting and ensure complete financial records, you must calculate the missing day’s sales based on the provided average and the available sales figures.\n",
        "\n",
        "\n",
        "Your task is to define a function restore_missing_sale(data) that accepts a list of daily sales with one missing value and the reported average, and returns the missing sale amount.\n",
        "\n",
        "\n",
        "Input Format\n",
        "\n",
        "A tuple containing two inputs in the following order:\n",
        "\n",
        "\n",
        "sales: A list of known daily sales values (float)\n",
        "sales_avg: The average daily sales (float) for the complete period including the missing day\n",
        "\n",
        "Output Format\n",
        "\n",
        "\n",
        "A single value (float) representing the missing sale amount\n",
        "\n",
        "Constraints\n",
        "\n",
        "The computed result is rounded to two decimals\n",
        "\n",
        "Example Case 1\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "([1200.0, 1350.0, 1280.0, 1420.0, 1500.0, 1300.0], 1371.43)  \n",
        "\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "\n",
        "1550.01\n",
        "\n",
        "\n",
        "\n",
        "Example Case 2\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "\n",
        "([1000.0, 1100.0, 1050.0, 1200.0, 1150.0, 1080.0], 1100.0)\n",
        "\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "\n",
        "1120.0"
      ],
      "metadata": {
        "id": "fPRQ8oGrgb2_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwMLMTTDJLGg",
        "outputId": "1712820e-f6c1-46d8-9d26-5fc7a03283db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([1000.0, 1100.0, 1050.0, 1200.0, 1150.0, 1080.0], 1100.0)\n",
            "1120.0\n"
          ]
        }
      ],
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "def restore_missing_sale(data):\n",
        "    sales = sum(data[0])\n",
        "    sales_total = data[1] * 7\n",
        "    return sales_total - sales\n",
        "\n",
        "\n",
        "# (do not edit)\n",
        "user_input = input()\n",
        "parsed_input = literal_eval(user_input)\n",
        "print(round(restore_missing_sale(parsed_input), 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are a data analyst at a ticketing platform that tracks user interest across a variety of events including concerts, plays, and sports. Understanding which events generate the most interaction is key for effective marketing and resource planning.\n",
        "\n",
        "\n",
        "Your task is to implement the function high_interest_events(data), which analyses the platform's interaction data and identifies which event(s) received the highest user interest.\n",
        "\n",
        "\n",
        "Input Format\n",
        "\n",
        "A list of event names (str) representing user interactions on the platform\n",
        "\n",
        "Output Format\n",
        "\n",
        "A list of event name(s) (str) that received the highest user interest, sorted in alphabetical order\n",
        "\n",
        "\n",
        "Constraints\n",
        "\n",
        "N/A\n",
        "\n",
        "\n",
        "Example Case 1\n",
        "\n",
        "Input\n",
        "\n",
        "['Concert', 'Concert', 'Play', 'Sports', 'Concert', 'Play']\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "['Concert']\n",
        "\n",
        "\n",
        "Example Case 2\n",
        "\n",
        "Input\n",
        "\n",
        "['Play', 'Play', 'Concert', 'Sports', 'Concert', 'Sports']\n",
        "\n",
        "Output\n",
        "\n",
        "['Concert', 'Play', 'Sports']"
      ],
      "metadata": {
        "id": "Zs7uCnhwnzZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "def verify_event_popularity(events):\n",
        "    event_dict = {}\n",
        "    for event in events:\n",
        "        if event in event_dict:\n",
        "            event_dict[event] += 1\n",
        "        else:\n",
        "            event_dict[event] = 1\n",
        "\n",
        "    max_value = max(event_dict.values())\n",
        "    max_keys = []\n",
        "    for key, value in event_dict.items():\n",
        "        if value == max_value:\n",
        "            max_keys.append(key)\n",
        "    max_keys.sort()\n",
        "    return max_keys\n",
        "\n",
        "\n",
        "# (do not edit)\n",
        "print(verify_event_popularity(literal_eval(input())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUowyLSGgz-a",
        "outputId": "eec95f72-a118-4120-d893-044c955d1039"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Rock', 'Rock', 'Jazz', 'Jazz', 'Jazz', 'Rock']\n",
            "['Jazz', 'Rock']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edumedic, a health-tech company managing remote patient monitoring systems, aims to enhance early detection of abnormal health trends among patients recovering at home. One of the most critical metrics tracked is body temperature, as it can be an early sign of infection, inflammation, or fever relapse.\n",
        "\n",
        "\n",
        "Your task is to develop an automated method to flag highly deviated temperature readings based on statistical analysis. Using historical temperature data for a group of patients, you are to identify any readings that lie significantly outside the typical temperature range, specifically those that fall beyond two standard deviation units from the average.\n",
        "\n",
        "\n",
        "Your task is to define a function flag_highly_deviated_temperatures(temperatures) that:\n",
        "\n",
        "\n",
        "Accepts a tuple of numerical values representing body temperature readings of patients\n",
        "Identifies and returns a list of temperature readings that are highly deviated — those that lie outside the range of two standard deviations from the mean temperature readings\n",
        "\n",
        "Input Format\n",
        "\n",
        "A tuple of values (float) representing temperature readings\n",
        "\n",
        "Output Format\n",
        "\n",
        "A list of temperature values (float) that are highly deviated from the average body temperature\n",
        "\n",
        "Constraints\n",
        "\n",
        "N/A\n",
        "\n",
        "Example Case 1\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "\n",
        "(98.6, 98.7, 98.8, 98.9, 99.0, 98.4, 98.5, 98.3, 98.6, 98.7)\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "\n",
        "[]\n",
        "\n",
        "\n",
        "\n",
        "Example Case 2\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "\n",
        "(98.6, 99.1, 97.5, 102.2, 98.7, 98.5, 98.9, 99.0, 98.8, 98.6)\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "\n",
        "[102.2]\n",
        "\n",
        "\n",
        "\n",
        "Calculate the mean of the input temperatures tuple.\n",
        "\n",
        "Calculate the standard deviation of the input temperatures tuple.\n",
        "\n",
        "Define the lower bound and upper bound of the acceptable range.\n",
        "\n",
        "Loop through each temperature in the input tuple.\n",
        "\n",
        "Inside the loop, check if the current temperature is outside of the acceptable range (i.e., it's less than the lower bound OR greater than the upper bound).\n",
        "\n",
        "If it is, add it to a list that we'll return at the end."
      ],
      "metadata": {
        "id": "vCLYaG5Ds8T7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "# removed math library\n",
        "\n",
        "def flag_highly_deviated_temperatures(temperatures):\n",
        "    # Code here\n",
        "    mean_temp = sum(temperatures) / len(temperatures)\n",
        "    # Calculate standard deviation without math.sqrt\n",
        "    std_dev = (sum([(x - mean_temp) ** 2 for x in temperatures]) / len(temperatures))**0.5\n",
        "\n",
        "    lower_bound = mean_temp - 2 * std_dev\n",
        "    upper_bound = mean_temp + 2 * std_dev\n",
        "\n",
        "    deviated_temps = []\n",
        "    for temp in temperatures:\n",
        "        if temp < lower_bound or temp > upper_bound:\n",
        "            deviated_temps.append(temp)\n",
        "\n",
        "    return deviated_temps\n",
        "\n",
        "\n",
        "# Input and output processing (do not edit)\n",
        "print(flag_highly_deviated_temperatures(literal_eval(input())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtFJKjdpp9MQ",
        "outputId": "e8c55d76-5cfe-4b25-d378-e748f312b5b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(98.6, 99.1, 97.5, 102.2, 98.7, 98.5, 98.9, 99.0, 98.8, 98.6)\n",
            "[102.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You work as a data analyst at Edurise, an ed-tech company offering competitive exam coaching. The academic team plans to provide early access to advanced mentoring and problem-solving resources to a very small group of students who scored higher than at least 95 percent of their peers in the batch.\n",
        "\n",
        "\n",
        "Your task is to define a function top_percentile_students(data) that accepts the student IDs and associated scores, and identifies and returns the IDs of the best performing students.\n",
        "\n",
        "\n",
        "Input Format\n",
        "\n",
        "\n",
        "A tuple of tuples, where each inner tuple contains:\n",
        "\n",
        "\n",
        "student_id: A value (int) representing the unique identifier assigned to each student in the top-ranker batch\n",
        "\n",
        "score: A number (int or float) indicating the mark secured by the student\n",
        "\n",
        "\n",
        "Output Format\n",
        "\n",
        "\n",
        "A list of values (int), each representing the student_id of a student whose score is greater than or equal to at least 95% of the batch\n",
        "\n",
        "The list must be sorted in ascending order\n",
        "Your percentile calculation must perform interpolation\n",
        "\n",
        "Constraints\n",
        "\n",
        "\n",
        "The input tuple contains at least two entries\n",
        "\n",
        "Example Case 1\n",
        "\n",
        "Input\n",
        "\n",
        "((101, 88.5), (102, 91.0), (103, 76.5), (104, 95.0), (105, 89.0), (106, 78.5),(107, 82.0), (108, 85.5), (109, 92.0), (110, 87.0), (111, 80.0), (112, 84.5),(113, 83.0), (114, 90.0), (115, 86.0), (116, 79.5), (117, 94.0), (118, 88.0), (119, 77.5), (120, 81.0), (121, 86.5), (122, 93.5), (123, 89.5), (124, 90.5),(125, 92.5), (126, 87.5), (127, 85.0), (128, 84.0), (129, 82.5), (130, 91.5))\n",
        "\n",
        "Output\n",
        "\n",
        "[104, 117]\n",
        "\n",
        "\n",
        "Example Case 2\n",
        "\n",
        "Input\n",
        "\n",
        "\n",
        "((1, 298), (2, 297), (3, 297), (4, 296), (5, 295),(6, 295), (7, 294), (8, 294), (9, 293), (10, 292))\n",
        "\n",
        "Output\n",
        "\n",
        "\n",
        "[1]"
      ],
      "metadata": {
        "id": "b0MLwULWYibi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "# removed math library\n",
        "\n",
        "def top_percentile_students(data):\n",
        "    # Sort data by score\n",
        "    sorted_data = sorted(data, key=lambda item: item[1])\n",
        "    scores = [item[1] for item in sorted_data]\n",
        "    n = len(scores)\n",
        "    percentile_rank = 0.95 * (n - 1)\n",
        "\n",
        "    # Calculate 95th percentile score with interpolation\n",
        "    if percentile_rank.is_integer():\n",
        "        percentile_score = scores[int(percentile_rank)]\n",
        "    else:\n",
        "        lower_index = int(percentile_rank) # Using int() for floor\n",
        "        upper_index = int(percentile_rank) + 1 # Using int() + 1 for ceiling\n",
        "        lower_score = scores[lower_index]\n",
        "        upper_score = scores[upper_index]\n",
        "        percentile_score = lower_score + (percentile_rank - lower_index) * (upper_score - lower_score)\n",
        "\n",
        "    # Identify student IDs with scores >= 95th percentile score\n",
        "    top_students = [student_id for student_id, score in data if score >= percentile_score]\n",
        "\n",
        "    # Sort the result in ascending order\n",
        "    top_students.sort()\n",
        "\n",
        "    return top_students\n",
        "\n",
        "# Input and output processing (do not edit)\n",
        "print(top_percentile_students(literal_eval(input())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro_itMGyx4iO",
        "outputId": "b417f3cc-ef07-4738-ec1e-e914beecb040"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((101, 88.5), (102, 91.0), (103, 76.5), (104, 95.0), (105, 89.0), (106, 78.5),(107, 82.0), (108, 85.5), (109, 92.0), (110, 87.0), (111, 80.0), (112, 84.5),(113, 83.0), (114, 90.0), (115, 86.0), (116, 79.5), (117, 94.0), (118, 88.0), (119, 77.5), (120, 81.0), (121, 86.5), (122, 93.5), (123, 89.5), (124, 90.5),(125, 92.5), (126, 87.5), (127, 85.0), (128, 84.0), (129, 82.5), (130, 91.5))\n",
            "[104, 117]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are part of the pricing strategy team at a national food chain that operates through independently managed franchise outlets. Each outlet sets its own prices for a common menu, leading to variation across locations.\n",
        "\n",
        "\n",
        "To improve pricing standardisation and ensure a consistent customer experience, your team wants to identify outlets whose pricing behaviour deviates from the most common pattern observed across the network.\n",
        "\n",
        "\n",
        "Each outlet reports a list of prices for its local menu. A pricing pattern is defined by two factors:\n",
        "\n",
        "\n",
        "The average menu price, and\n",
        "The standard deviation of those prices (i.e., price consistency)\n",
        "\n",
        "The most common pattern across all outlets is treated as the baseline. Any outlet that does not follow this common pricing pattern should be flagged for review.\n",
        "\n",
        "\n",
        "Write a function identify_non_standard_outlets(outlet_data) that:\n",
        "\n",
        "\n",
        "Identifies the most common pricing pattern based on rounded average and standard deviation\n",
        "Returns the names of all outlets that do not follow this pattern, in alphabetical order\n",
        "If all outlets follow the same pattern, return the string 'All outlets aligned'\n",
        "\n",
        "\n",
        "Input Format\n",
        "\n",
        "A tuple of tuples, where each inner tuple contains:\n",
        "\n",
        "outlet_name: a string (str) representing the name of the outlet\n",
        "menu_prices: a list of values (float) representing the prices of items at that outlet\n",
        "\n",
        "Output Format\n",
        "\n",
        "A list of outlet names (str) that do not match the common pricing pattern\n",
        "Or a string 'All outlets aligned' if no such outlets exist\n",
        "\n",
        "Constraints\n",
        "\n",
        "The number of outlets is at least 3\n",
        "Each outlet has at least 3 price values\n",
        "All prices are non-negative floats\n",
        "Average and standard deviation must be rounded down to the nearest integer before comparison\n",
        "An outlet is considered non-standard if its rounded average and standard deviation do not match the most common combination\n",
        "\n",
        "Example Case 1\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "\n",
        "((\"OutletA\", [100, 200, 300]),  (\"OutletB\", [150, 200, 250]),  (\"OutletC\", [100, 200, 300]),  (\"OutletD\", [200, 300, 400]),  (\"OutletE\", [100, 200, 300]),  (\"OutletF\", [150, 200, 250]))\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "\n",
        "['OutletB', 'OutletD', 'OutletF']\n",
        "\n",
        "\n",
        "\n",
        "Example Case 2\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "\n",
        "((\"OutletA\", [10, 20, 30, 40]),  (\"OutletB\", [10, 20, 30, 40]),  (\"OutletC\", [10, 20, 30, 40]),  (\"OutletD\", [10, 20, 30, 40]),  (\"OutletE\", [10, 20, 30, 40]),  (\"OutletF\", [10, 20, 30, 40]))\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "\n",
        "All outlets aligned"
      ],
      "metadata": {
        "id": "rqNZcc29cJoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "# removed collections library\n",
        "\n",
        "def identify_non_standard_outlets(outlet_data):\n",
        "    patterns = []\n",
        "    for outlet_name, menu_prices in outlet_data:\n",
        "        mean_price = sum(menu_prices) / len(menu_prices)\n",
        "        # Calculate standard deviation\n",
        "        std_dev = (sum([(x - mean_price) ** 2 for x in menu_prices]) / len(menu_prices))**0.5\n",
        "\n",
        "        # Round down to the nearest integer\n",
        "        rounded_mean = int(mean_price)\n",
        "        rounded_std_dev = int(std_dev)\n",
        "\n",
        "        patterns.append(((rounded_mean, rounded_std_dev), outlet_name))\n",
        "\n",
        "    # Find the most common pattern without using collections.Counter\n",
        "    pattern_counts = {}\n",
        "    for pattern, _ in patterns:\n",
        "        if pattern in pattern_counts:\n",
        "            pattern_counts[pattern] += 1\n",
        "        else:\n",
        "            pattern_counts[pattern] = 1\n",
        "\n",
        "    most_common_pattern = None\n",
        "    max_count = 0\n",
        "    for pattern, count in pattern_counts.items():\n",
        "        if count > max_count:\n",
        "            max_count = count\n",
        "            most_common_pattern = pattern\n",
        "\n",
        "    # Identify outlets that don't follow the most common pattern\n",
        "    non_standard_outlets = [outlet_name for pattern, outlet_name in patterns if pattern != most_common_pattern]\n",
        "\n",
        "    # Sort the result in alphabetical order\n",
        "    non_standard_outlets.sort()\n",
        "\n",
        "    if not non_standard_outlets:\n",
        "        return \"All outlets aligned\"\n",
        "    else:\n",
        "        return non_standard_outlets\n",
        "\n",
        "\n",
        "# Input and output processing (do not edit)\n",
        "print(identify_non_standard_outlets(literal_eval(input())))"
      ],
      "metadata": {
        "id": "_U4YPk4VaNlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are a data analyst at an e-commerce platform that revises its product pricing and promotional strategies every two weeks. To make informed decisions, the company wishes to understand how product prices influence customer engagement on the platform.\n",
        "\n",
        "\n",
        "Your goal is to examine whether there is a strong, weak, or neutral relationship between product price and average time spent by the customer on the corresponding product page.\n",
        "\n",
        "\n",
        "Your task is to define a function analyze_price_time_relation(data) that accepts product prices and average time spent by customers on each corresponding product pages, calculates the correlation between product prices and time spent, and returns one of the following based on the correlation:\n",
        "\n",
        "\n",
        "'Strong' – if the absolute correlation is ≥ 0.7\n",
        "'Weak'– if the absolute correlation is between 0.3 and 0.7\n",
        "'Neutral'– if the absolute correlation is < 0.3\n",
        "\n",
        "Input Format\n",
        "\n",
        "\n",
        "A tuple of two tuples:\n",
        "\n",
        "\n",
        "product_prices: The first tuple includes product prices (float)\n",
        "\n",
        "time_spent: The second tuple includes the average time (float) spent by customers on each respective product page\n",
        "\n",
        "\n",
        "Output Format\n",
        "\n",
        "\n",
        "A single value (str) indicating the strength of the relationship between product price and time spent\n",
        "\n",
        "Constraints\n",
        "\n",
        "N/A\n",
        "\n",
        "\n",
        "Example Case 1  \n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "\n",
        "((100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750), (2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5))\n",
        "\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "Strong\n",
        "\n",
        "\n",
        "\n",
        "Example Case 2\n",
        "\n",
        "Input\n",
        "\n",
        "((100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155, 160, 165),    (5.0, 5.1, 5.2, 5.1, 5.0, 5.1, 5.2, 5.0, 5.1, 5.2, 5.0, 5.1, 5.2, 5.0))\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "Neutral"
      ],
      "metadata": {
        "id": "3H0RH8zii_BL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_price_time_relation(data):\n",
        "    \"\"\"\n",
        "    Analyzes the correlation between product prices and average time spent on product pages.\n",
        "\n",
        "    Args:\n",
        "        data: A tuple of two tuples. The first contains product prices (floats)\n",
        "              and the second contains average time spent (floats).\n",
        "\n",
        "    Returns:\n",
        "        A string indicating the strength of the relationship ('Strong', 'Weak', or 'Neutral').\n",
        "    \"\"\"\n",
        "    # Unpack the two tuples from the input data\n",
        "    prices = data[0]\n",
        "    times_spent = data[1]\n",
        "\n",
        "    # Calculate the mean of each list.\n",
        "    mean_prices = sum(prices) / len(prices)\n",
        "    mean_times = sum(times_spent) / len(times_spent)\n",
        "\n",
        "    # Calculate the numerator of the Pearson correlation formula (Covariance).\n",
        "    # This is the sum of the products of the deviations from the mean.\n",
        "    numerator = sum((prices[i] - mean_prices) * (times_spent[i] - mean_times) for i in range(len(prices)))\n",
        "\n",
        "    # Calculate the two components of the denominator (product of standard deviations).\n",
        "    # This involves the sum of the squared deviations from the mean for each list.\n",
        "    price_deviations_squared = sum((p - mean_prices) ** 2 for p in prices)\n",
        "    time_deviations_squared = sum((t - mean_times) ** 2 for t in times_spent)\n",
        "\n",
        "    # Check for an edge case where there is no variance in one of the data sets.\n",
        "    # This would cause a division by zero. In this case, correlation is undefined.\n",
        "    if price_deviations_squared == 0 or time_deviations_squared == 0:\n",
        "        return 'Neutral'\n",
        "\n",
        "    # Calculate the denominator (square root of the product of the squared deviations).\n",
        "    denominator = (price_deviations_squared * time_deviations_squared) ** 0.5\n",
        "\n",
        "    # Calculate the final correlation coefficient.\n",
        "    correlation = numerator / denominator\n",
        "\n",
        "    # Determine the strength of the relationship based on the absolute correlation.\n",
        "    absolute_correlation = abs(correlation)\n",
        "\n",
        "    if absolute_correlation >= 0.7:\n",
        "        return 'Strong'\n",
        "    elif 0.3 <= absolute_correlation < 0.7:\n",
        "        return 'Weak'\n",
        "    else:  # absolute_correlation < 0.3\n",
        "        return 'Neutral'\n",
        "\n",
        "# Example Case 1\n",
        "case1_input = ((100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750),\n",
        "               (2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5))\n",
        "case1_output = analyze_price_time_relation(case1_input)\n",
        "print(f\"Example Case 1 Output: {case1_output}\")\n",
        "\n",
        "# Example Case 2\n",
        "case2_input = ((100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155, 160, 165),\n",
        "               (5.0, 5.1, 5.2, 5.1, 5.0, 5.1, 5.2, 5.0, 5.1, 5.2, 5.0, 5.1, 5.2, 5.0))\n",
        "case2_output = analyze_price_time_relation(case2_input)\n",
        "print(f\"Example Case 2 Output: {case2_output}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RGPw6DJjDoV",
        "outputId": "496df6f9-1144-4501-a913-aeb75591694b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example Case 1 Output: Strong\n",
            "Example Case 2 Output: Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are a quantitative analyst at a major investment firm. Your primary role involves assessing the risk associated with various financial portfolios. A key aspect of risk analysis is understanding the volatility of returns, which is quantified by measures of variability. The higher the variability, the higher the perceived risk.\n",
        "\n",
        "\n",
        "You are given a series of daily percentage returns for a specific investment portfolio over a period. Your task is to calculate two critical risk metrics: the Population Variance and the Population Standard Deviation of these daily returns. Additionally, you need to determine if the portfolio's volatility exceeds predefined acceptable thresholds for both metrics.\n",
        "\n",
        "\n",
        "Input Format\n",
        "\n",
        "A tuple containing three elements:\n",
        "\n",
        "\n",
        "A list of daily percentage returns (float or int) for the portfolio\n",
        "\n",
        "A positive float specifying the acceptable variance threshold\n",
        "\n",
        "A positive float specifying the acceptable standard deviation threshold\n",
        "\n",
        "\n",
        "Output Format\n",
        "\n",
        "The function returns a string describing the portfolio's risk level:\n",
        "\n",
        "\n",
        "'High Risk: Exceeds Both Thresholds' – if both variance and standard deviation exceed their thresholds\n",
        "'Moderate Risk: High Variance Only' – if only variance exceeds its threshold\n",
        "'Moderate Risk: High Standard Deviation Only' – if only standard deviation exceeds its threshold\n",
        "'Low Risk: Within Acceptable Limits' – if neither exceeds the\n",
        "\n",
        "Constraints\n",
        "\n",
        "The daily_returns list contains at least 2 return value\n",
        "If the list contains only 1 return value, the variance and standard deviation are treated as 0, and the portfolio will be classified as 'Low Risk: Within Acceptable Limits'.\n",
        "\n",
        "Example Case 1\n",
        "\n",
        "Input\n",
        "\n",
        "([0.02, -0.01, 0.03, 0.05, -0.02, 0.01], 0.0005, 0.02)\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "\n",
        "High Risk: Exceeds Both Thresholds\n",
        "\n",
        "\n",
        "Example Case 2\n",
        "\n",
        "Input\n",
        "\n",
        "([0.001, 0.002, 0.0015, 0.0025, 0.001], 0.0001, 0.01)\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "Low Risk: Within Acceptable Limits"
      ],
      "metadata": {
        "id": "nC8f_ylXoIgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "def analyze_portfolio_risk(data):\n",
        "    \"\"\"\n",
        "    Analyzes the risk of a portfolio based on its daily returns,\n",
        "    population variance, and population standard deviation.\n",
        "\n",
        "    Args:\n",
        "        data: A tuple containing:\n",
        "            - daily_returns: A list of daily percentage returns (float or int).\n",
        "            - variance_threshold: The acceptable variance threshold (float).\n",
        "            - std_dev_threshold: The acceptable standard deviation threshold (float).\n",
        "\n",
        "    Returns:\n",
        "        A string describing the portfolio's risk level.\n",
        "    \"\"\"\n",
        "    daily_returns, variance_threshold, std_dev_threshold = data\n",
        "\n",
        "    if len(daily_returns) <= 1:\n",
        "        return 'Low Risk: Within Acceptable Limits'\n",
        "\n",
        "    mean_return = sum(daily_returns) / len(daily_returns)\n",
        "\n",
        "    # Calculate Population Variance\n",
        "    population_variance = sum([(x - mean_return) ** 2 for x in daily_returns]) / len(daily_returns)\n",
        "\n",
        "    # Calculate Population Standard Deviation\n",
        "    population_std_dev = population_variance ** 0.5\n",
        "\n",
        "    exceeds_variance = population_variance > variance_threshold\n",
        "    exceeds_std_dev = population_std_dev > std_dev_threshold\n",
        "\n",
        "    if exceeds_variance and exceeds_std_dev:\n",
        "        return 'High Risk: Exceeds Both Thresholds'\n",
        "    elif exceeds_variance:\n",
        "        return 'Moderate Risk: High Variance Only'\n",
        "    elif exceeds_std_dev:\n",
        "        return 'Moderate Risk: High Standard Deviation Only'\n",
        "    else:\n",
        "        return 'Low Risk: Within Acceptable Limits'\n",
        "\n",
        "# Input and output processing (do not edit)\n",
        "user_input = literal_eval(input())\n",
        "print(analyze_portfolio_risk(user_input))"
      ],
      "metadata": {
        "id": "bldr61TvjI5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You work as a data analyst at Edurise, an ed-tech company offering competitive exam coaching. The product team is aiming to enhance personalised learning recommendations by studying weekly student engagement patterns. They are particularly interested in understanding if students who invest more time on the platform are also more likely to engage actively with practice questions.\n",
        "\n",
        "\n",
        "Your task is to define a function compute_covariance(data) that accepts the time spent on the platform by students as well as the questions attempted by students, and computes and returns the covariance between these two metrics\n",
        "\n",
        "\n",
        "Input Format\n",
        "\n",
        "\n",
        "A tuple of two tuples, each containing 7 numerical values:\n",
        "\n",
        "\n",
        "The first tuple represents the time spent (in minutes) (int) on the platform each day in a week\n",
        "\n",
        "The second tuple represents the number of questions (int) attempted each day in a week\n",
        "\n",
        "\n",
        "Output Format\n",
        "\n",
        "\n",
        "A single value (float) representing the covariance between time spent on the platform and number of questions attempted\n",
        "\n",
        "Constraints\n",
        "\n",
        "\n",
        "The final result is rounded to 2 decimal places\n",
        "\n",
        "\n",
        "Example Case 1\n",
        "\n",
        "Input\n",
        "\n",
        "((45, 59, 40, 35, 66, 79, 72), (29, 22, 33, 43, 48, 42, 50))\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "58.49\n",
        "\n",
        "\n",
        "Example Case 2\n",
        "\n",
        "Input\n",
        "\n",
        "((30, 35, 40, 38, 42, 45, 50), (60, 55, 50, 52, 48, 45, 40))\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "-36.86"
      ],
      "metadata": {
        "id": "6UV-899Koz-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "def compute_covariance(data):\n",
        "    \"\"\"\n",
        "    Computes the covariance between two sets of data.\n",
        "\n",
        "    Args:\n",
        "        data: A tuple of two tuples, each containing numerical values.\n",
        "              The first tuple represents time spent, the second represents questions attempted.\n",
        "\n",
        "    Returns:\n",
        "        A float representing the covariance, rounded to 2 decimal places.\n",
        "    \"\"\"\n",
        "    time_spent = data[0]\n",
        "    questions_attempted = data[1]\n",
        "\n",
        "    n = len(time_spent)\n",
        "    mean_time = sum(time_spent) / n\n",
        "    mean_questions = sum(questions_attempted) / n\n",
        "\n",
        "    covariance = sum([(time_spent[i] - mean_time) * (questions_attempted[i] - mean_questions) for i in range(n)]) / n\n",
        "\n",
        "    return round(covariance, 2)\n",
        "\n",
        "# Input and output processing (do not edit)\n",
        "print(compute_covariance(literal_eval(input())))"
      ],
      "metadata": {
        "id": "ITjYY2-eo0jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are working with a support operations team that tracks customer wait times across multiple service regions. The team uses these wait times to measure how well each region complies with its Service Level Agreement (SLA).\n",
        "\n",
        "\n",
        "According to the SLA, the median wait time in any region should not exceed a specified threshold (in minutes). Your task is to identify all regions that fail to meet this SLA requirement.\n",
        "\n",
        "\n",
        "Write a function failing_regions(wait_data, sla) that computes the median wait time for each region and returns the names of regions where the median wait time is greater than the SLA threshold.\n",
        "\n",
        "\n",
        "Input Format\n",
        "\n",
        "\n",
        "A tuple with two elements:\n",
        "\n",
        "wait_data: A dictionary where each key is a region name (string) and each value is a list of wait times (float) in minutes\n",
        "sla: A value (float) representing the SLA threshold\n",
        "\n",
        "Output Format\n",
        "\n",
        "A list of region names (str) whose median wait time exceeds the SLA threshold, sorted in alphabetical order\n",
        "If all regions comply with the SLA, return the string 'All regions meet SLA'\n",
        "\n",
        "Constraints\n",
        "\n",
        "All wait time values are non-negative floats\n",
        "SLA threshold values are non-negative floats\n",
        "Round the median wait time to two decimal places before comparing it with the SLA threshold\n",
        "\n",
        "\n",
        "Example Case 1\n",
        "\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "(\n",
        "\n",
        "    {\n",
        "\n",
        "        \"North\": [5.0, 7.2, 6.8, 8.0, 9.1, 6.5, 7.0],\n",
        "\n",
        "        \"South\": [12.5, 13.0, 14.1, 15.2, 12.0, 14.8],\n",
        "\n",
        "        \"East\": [6.0, 6.1, 6.2, 6.3, 6.4, 6.5],\n",
        "\n",
        "        \"West\": [10.0, 10.5, 9.8, 11.2, 10.3]\n",
        "\n",
        "    },\n",
        "\n",
        "    10.0\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "[\"South\", \"West\"]\n",
        "\n",
        "\n",
        "Example Case 2\n",
        "\n",
        "Input\n",
        "\n",
        "(\n",
        "\n",
        "    {\n",
        "\n",
        "        \"North\": [2.0, 2.5, 3.0, 3.5, 4.0],\n",
        "\n",
        "        \"South\": [9.9, 10.0, 10.1, 10.0, 10.2],\n",
        "\n",
        "        \"East\": [5.0, 5.5, 6.0, 5.5, 6.0],\n",
        "\n",
        "        \"West\": [7.0, 6.5, 7.5, 7.0, 6.8]\n",
        "\n",
        "    },\n",
        "\n",
        "    9.5\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "[\"South\"]"
      ],
      "metadata": {
        "id": "U1IXBgTuqB9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "def failing_regions(data):\n",
        "    \"\"\"\n",
        "    Identifies regions where the median wait time exceeds the SLA threshold.\n",
        "\n",
        "    Args:\n",
        "        data: A tuple containing:\n",
        "            - wait_data: A dictionary with region names as keys and lists of wait times as values.\n",
        "            - sla: The SLA threshold (float).\n",
        "\n",
        "    Returns:\n",
        "        A list of region names exceeding the SLA, sorted alphabetically,\n",
        "        or \"All regions meet SLA\" if none exceed.\n",
        "    \"\"\"\n",
        "    wait_data, sla = data\n",
        "    failing = []\n",
        "\n",
        "    for region, wait_times in wait_data.items():\n",
        "        sorted_wait_times = sorted(wait_times)\n",
        "        n = len(sorted_wait_times)\n",
        "        if n % 2 == 0:\n",
        "            median = (sorted_wait_times[n // 2 - 1] + sorted_wait_times[n // 2]) / 2\n",
        "        else:\n",
        "            median = sorted_wait_times[n // 2]\n",
        "\n",
        "        rounded_median = round(median, 2)\n",
        "\n",
        "        if rounded_median > sla:\n",
        "            failing.append(region)\n",
        "\n",
        "    failing.sort()\n",
        "\n",
        "    if not failing:\n",
        "        return \"All regions meet SLA\"\n",
        "    else:\n",
        "        return failing\n",
        "\n",
        "# Input and output processing (do not edit)\n",
        "print(failing_regions(literal_eval(input())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F1j9qPaqCg4",
        "outputId": "79ab58ee-5879-4d55-d8d6-30ffdaa90a4a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(     {         \"North\": [5.0, 7.2, 6.8, 8.0, 9.1, 6.5, 7.0],         \"South\": [12.5, 13.0, 14.1, 15.2, 12.0, 14.8],         \"East\": [6.0, 6.1, 6.2, 6.3, 6.4, 6.5],         \"West\": [10.0, 10.5, 9.8, 11.2, 10.3]     },     10.0 )\n",
            "['South', 'West']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are helping a wellness platform analyse data from wearable devices that track heart rate and sleep duration. The goal is to detect users whose heart rate is strongly negatively correlated with their sleep duration — a potential indicator of chronic stress or burnout.\n",
        "\n",
        "\n",
        "Each user’s wearable data consists of several daily records, where each record logs the average heart rate and corresponding sleep duration for that day.\n",
        "\n",
        "\n",
        "You have been asked to identify all users who show a strong negative correlation (≤ –0.70) between their heart rate and sleep duration. This correlation must be computed manually, without using any external libraries.\n",
        "\n",
        "\n",
        "Write a function find_stress_linked_users(user_data) that calculates the Pearson correlation coefficient between heart rate and sleep duration for each user and returns the names of users who show a strong negative correlation (≤ –0.70)\n",
        "\n",
        "Input Format\n",
        "\n",
        "A tuple of tuples, where each inner tuple contains:\n",
        "\n",
        "user_id: a string representing the user’s ID\n",
        "records: a list of tuples (float, float) representing daily records in the form (heart_rate, sleep_duration)\n",
        "Output Format\n",
        "\n",
        "A list of user IDs (str) whose rounded correlation coefficient is ≤ –0.70, sorted in alphabetical order\n",
        "If no such users exist, return the string 'No stress-linked patterns detected'\n",
        "\n",
        "Constraints\n",
        "\n",
        "All values are non-negative floats\n",
        "Round the final correlation to 2 decimal places before comparison\n",
        "\n",
        "Example Case 1\n",
        "\n",
        "Input\n",
        "\n",
        "(('U1', [(70, 6), (75, 6), (80, 6), (85, 6), (90, 6)]),\n",
        "\n",
        " ('U2', [(90, 4), (85, 5), (80, 6), (75, 7), (70, 8)]),\n",
        "\n",
        " ('U3', [(60, 7), (65, 7.1), (70, 7.2), (75, 7.3), (80, 7.4)]))\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "['U2']\n",
        "\n",
        "\n",
        "\n",
        "Example Case 2\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "\n",
        "(('U1', [(70, 6), (75, 6.5), (80, 6), (85, 6.5), (90, 6)]),\n",
        "\n",
        " ('U2', [(90, 5), (90, 5), (90, 5), (90, 5), (90, 5)]),\n",
        "\n",
        " ('U3', [(60, 7), (65, 6.8), (70, 7.1), (75, 6.9), (80, 7)]))\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "\n",
        "No stress-linked patterns detected"
      ],
      "metadata": {
        "id": "_zcCzXK5tKu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "def find_stress_linked_users(user_data):\n",
        "    \"\"\"\n",
        "    Identifies users with a strong negative correlation between heart rate and sleep duration.\n",
        "\n",
        "    Args:\n",
        "        user_data: A tuple of tuples, where each inner tuple contains:\n",
        "            - user_id: A string representing the user’s ID.\n",
        "            - records: A list of tuples (float, float) representing daily records (heart_rate, sleep_duration).\n",
        "\n",
        "    Returns:\n",
        "        A list of user IDs (str) whose rounded correlation coefficient is ≤ –0.70, sorted alphabetically,\n",
        "        or \"No stress-linked patterns detected\" if no such users exist.\n",
        "    \"\"\"\n",
        "    stress_linked_users = []\n",
        "\n",
        "    for user_id, records in user_data:\n",
        "        if len(records) < 2:\n",
        "            continue # Cannot calculate correlation with less than 2 data points\n",
        "\n",
        "        heart_rates = [record[0] for record in records]\n",
        "        sleep_durations = [record[1] for record in records]\n",
        "        n = len(records)\n",
        "\n",
        "        # Calculate means\n",
        "        mean_heart_rate = sum(heart_rates) / n\n",
        "        mean_sleep_duration = sum(sleep_durations) / n\n",
        "\n",
        "        # Calculate numerator (covariance)\n",
        "        numerator = sum([(heart_rates[i] - mean_heart_rate) * (sleep_durations[i] - mean_sleep_duration) for i in range(n)])\n",
        "\n",
        "        # Calculate denominators (product of standard deviations)\n",
        "        heart_rate_deviations_squared = sum([(hr - mean_heart_rate) ** 2 for hr in heart_rates])\n",
        "        sleep_duration_deviations_squared = sum([(sd - mean_sleep_duration) ** 2 for sd in sleep_durations])\n",
        "\n",
        "        denominator = (heart_rate_deviations_squared * sleep_duration_deviations_squared) ** 0.5\n",
        "\n",
        "        # Calculate correlation coefficient\n",
        "        if denominator == 0:\n",
        "            correlation = 0.0 # Handle cases with no variance\n",
        "        else:\n",
        "            correlation = numerator / denominator\n",
        "\n",
        "        # Round correlation to 2 decimal places\n",
        "        rounded_correlation = round(correlation, 2)\n",
        "\n",
        "        # Check for strong negative correlation\n",
        "        if rounded_correlation <= -0.70:\n",
        "            stress_linked_users.append(user_id)\n",
        "\n",
        "    # Sort the result in alphabetical order\n",
        "    stress_linked_users.sort()\n",
        "\n",
        "    if not stress_linked_users:\n",
        "        return \"No stress-linked patterns detected\"\n",
        "    else:\n",
        "        return stress_linked_users\n",
        "\n",
        "# Input and output processing (do not edit)\n",
        "print(find_stress_linked_users(literal_eval(input())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L2F2KlHqjHl",
        "outputId": "3fd6352c-6fb4-4635-8f9d-1c88af8c1d0c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(('U1', [(70, 6), (75, 6.5), (80, 6), (85, 6.5), (90, 6)]),  ('U2', [(90, 5), (90, 5), (90, 5), (90, 5), (90, 5)]),  ('U3', [(60, 7), (65, 6.8), (70, 7.1), (75, 6.9), (80, 7)]))\n",
            "No stress-linked patterns detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hMS9G_0uuaoh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}